import os
from pathlib import Path
import argparse
import re
import json
import logging
import shutil
import filetype
import subprocess
from datetime import datetime
import pytz
import pprint
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- å…¨å±€å˜é‡ ---
# è®¾ç½®æœ¬åœ°æ—¶åŒº
local_timezone = pytz.timezone("Asia/Shanghai")

# æ–‡ä»¶æ‰©å±•å
image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.tif', '.webp', '.heic', '.heif', '.raw', '.cr2', '.nef', '.arw'}
video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.mpg', '.mpeg', '.3gp', '.mts', '.m2ts'}
media_extensions = image_extensions | video_extensions
json_extensions = {'.json'}

# --- è¾…åŠ©å‡½æ•° ---
# è·å–è¾“å…¥çš„å‰45ä¸ªå­—ç¬¦
def get_file_name_cut(any_str, length=45):
    return any_str[:length]  # è¿”å›æ–‡ä»¶çš„å‰45ä¸ªå­—ç¬¦ï¼ŒåŒ…æ‹¬æ‰©å±•å


# æ›´æ–°jsonä¸­çš„titleå€¼, æŠŠtitleå€¼æ›´æ–°ä¸ºç°åœ¨mediaçš„full_name
def update_json_key_title(media_path, json_path):
    '''
    update_json_key_title çš„ Docstring
    ç»™å®šåª’ä½“æ–‡ä»¶è·¯å¾„å’Œå¯¹åº”çš„ JSON æ–‡ä»¶è·¯å¾„ï¼Œæ›´æ–° JSON æ–‡ä»¶ä¸­çš„ title å­—æ®µä¸ºåª’ä½“æ–‡ä»¶çš„å®Œæ•´æ–‡ä»¶å
    '''
    try:
        data = json.loads(json_path.read_text(encoding="utf-8"))  # ä»jsonä¸­è¯»å–æ•°æ®
        data["title"] = Path(media_path).name  # è‰ç¨¿æ›´æ”¹titleå€¼çš„æ‰©å±•å
        json_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")  # æŠŠè‰ç¨¿æ•°æ®å†™å…¥æ–‡ä»¶
    except Exception as e:
        logging.error(f"- æ›´æ–°json {Path(json_path).name} çš„titleæ—¶å‡ºé”™: {e}")


# ä¿®æ”¹æ–‡ä»¶ç³»ç»Ÿæ—¶é—´ (å…¼å®¹ Windows åˆ›å»ºæ—¶é—´)
def set_file_times(file_path, timestamp):
    '''
    set_file_times çš„ Docstring
    ç»™å®šä¸€ä¸ªæ–‡ä»¶è·¯å¾„å’Œæ—¶é—´æˆ³ï¼Œä¿®æ”¹è¯¥æ–‡ä»¶çš„è®¿é—®æ—¶é—´ã€ä¿®æ”¹æ—¶é—´å’Œåˆ›å»ºæ—¶é—´
    '''
    try:
        # ä¿®æ”¹è®¿é—®æ—¶é—´å’Œä¿®æ”¹æ—¶é—´ (è·¨å¹³å°)
        os.utime(file_path, (timestamp, timestamp))
        # Windowsä¸‹ä¿®æ”¹åˆ›å»ºæ—¶é—´éœ€è¦ç‰¹æ®Šå¤„ç†
        if os.name == 'nt':
            try:
                from ctypes import windll, wintypes, byref
                # è½¬æ¢æ—¶é—´æˆ³ä¸º Windows FileTime (100çº³ç§’é—´éš”ï¼Œè‡ª1601å¹´1æœˆ1æ—¥)
                timestamp_int = int(timestamp * 10000000) + 116444736000000000
                ctime = wintypes.FILETIME(timestamp_int & 0xFFFFFFFF, timestamp_int >> 32)
                
                # æ‰“å¼€æ–‡ä»¶å¥æŸ„
                handle = windll.kernel32.CreateFileW(str(file_path), 256, 0, None, 3, 128, None)
                if handle != -1:
                    # è®¾ç½®åˆ›å»ºæ—¶é—´ï¼Œæœ€åä¸¤ä¸ª None æ˜¯è®¿é—®æ—¶é—´å’Œä¿®æ”¹æ—¶é—´(ä¸Šé¢utimeå·²ç»æ”¹äº†ï¼Œè¿™é‡Œä¸ç”¨åŠ¨)
                    windll.kernel32.SetFileTime(handle, byref(ctime), None, None)
                    windll.kernel32.CloseHandle(handle)
            except Exception as e:
                logging.error(f"{file_path}Windowsåˆ›å»ºæ—¶é—´ä¿®æ”¹å¤±è´¥: {e}")
    except Exception as e:
        logging.error(f"{file_path}æ—¶é—´æˆ³ä¿®æ”¹å¤±è´¥: {e}")


# é˜¶æ®µ 1: éå†æ‰€æœ‰æ–‡ä»¶, å»ºç«‹æ–‡ä»¶åˆ—è¡¨
def collect_all_files(directory, extensions):
    '''
    collect_all_files çš„ Docstring
    éå†ç›®å½•ï¼Œæ”¶é›†æŒ‡å®šæ‰©å±•åçš„æ‰€æœ‰æ–‡ä»¶
    '''
    all_files = []
    for root, _, names in os.walk(directory):
        for name in names:
            file_path = Path(root) / name
            suffix = file_path.suffix.lower()
            if suffix in extensions:
                all_files.append(file_path)
    return all_files

def get_media_name_part_cut(media_file):
    '''
    get_media_name_part_cut çš„ Docstring
    ç»™å®šä¸€ä¸ªåª’ä½“æ–‡ä»¶è·¯å¾„, æå–å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†åŠå…¶å‰45ä¸ªå­—ç¬¦
    '''
    media_fullname = media_file.name  # å¸¦æ‰©å±•åçš„å®Œæ•´æ–‡ä»¶å
    media_stem = media_file.stem  # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
    media_ext = media_file.suffix  # æ–‡ä»¶æ‰©å±•å
    # è·å–å‰45ä¸ªå­—ç¬¦
    media_fullname_cut = get_file_name_cut(media_fullname)  # è·å–åª’ä½“æ–‡ä»¶å‰45ä¸ªå­—ç¬¦ï¼ŒåŒ…æ‹¬æ‰©å±•å
    media_stem_cut = get_file_name_cut(media_stem)  #  è·å–åª’ä½“æ–‡ä»¶åŸºåå‰45ä¸ªå­—ç¬¦
    # å¤„ç†å»é‡ç¼–å·
    media_dup_suffix = re.search(r"\(\d{1,2}\)$", media_stem)  # æŸ¥æ‰¾æ–‡ä»¶åæœ«å°¾çš„å»é‡ç¼–å·ï¼ˆå¦‚(1), (2)ï¼‰
    media_fullname_no_dup_cut = ""
    media_stem_no_dup_cut = ""
    if media_dup_suffix:
        media_dup_suffix = media_dup_suffix.group(0)  # æå–åŒ¹é…çš„å»é‡ç¼–å·å­—ç¬¦ä¸²
        media_fullname_no_dup = media_stem[:-len(media_dup_suffix)] + media_ext  # ä»å®Œæ•´æ–‡ä»¶åé‡Œå»æ‰å»é‡ç¼–å·ï¼Œè·å–å‰©ä½™æ–‡ä»¶å
        media_stem_no_dup = media_stem[:-len(media_dup_suffix)]  # ä»åŸºåé‡Œå»æ‰å»é‡ç¼–å·ï¼Œè·å–å‰©ä½™åŸºå
        media_fullname_no_dup_cut = get_file_name_cut(media_fullname_no_dup)  #  ä»ä¸Šé¢çš„æ–‡ä»¶åé‡Œè·å–å‰45ä¸ªå­—ç¬¦
        media_stem_no_dup_cut = get_file_name_cut(media_stem_no_dup)  #  ä»ä¸Šé¢çš„åŸºåé‡Œè·å–å‰45ä¸ªå­—ç¬¦
    return (media_fullname_cut, media_stem_cut, media_dup_suffix, media_fullname_no_dup_cut, media_stem_no_dup_cut)


def get_json_media_name_part_cut(json_file):
    '''
    get_json_media_name_parts çš„ Docstring
    ç»™å®šä¸€ä¸ª JSON æ–‡ä»¶è·¯å¾„, æå–å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†åŠå…¶å‰45ä¸ªå­—ç¬¦
    '''
    json_stem = json_file.stem  # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
    json_stem_no_dup = json_stem
    json_dup_suffix = re.search(r"\(\d{1,2}\)$", json_stem)  # æŸ¥æ‰¾ JSON æ–‡ä»¶åæœ«å°¾çš„å»é‡ç¼–å·
    if json_dup_suffix:
        json_dup_suffix = json_dup_suffix.group(0)  # æå–åŒ¹é…çš„å»é‡ç¼–å·å­—ç¬¦ä¸²
        json_stem_no_dup = json_stem[:-len(json_dup_suffix)]  # ä»åŸºåé‡Œå»æ‰å»é‡ç¼–å·ï¼Œè·å–å‰©ä½™åŸºå
    json_stem_no_dup_parts = json_stem_no_dup.split('.')  # ç”¨"."åˆ†å‰²å»é‡åçš„åŸºå
    if len(json_stem_no_dup_parts) >= 2 and ("."+json_stem_no_dup_parts[1].lower()) in media_extensions:
        ext_in_stem = "." + json_stem_no_dup_parts[1]  # æ ‡è®°æ‰©å±•ååœ¨åŸºåä¸­
        json_media_name_part = json_stem_no_dup_parts[0] + ext_in_stem  # å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†
    else:
        ext_in_stem = None  # æ ‡è®°æ‰©å±•åä¸åœ¨åŸºåä¸­
        json_media_name_part = json_stem_no_dup_parts[0]  # å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†
    json_media_name_part_cut = get_file_name_cut(json_media_name_part)  # è·å–å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†çš„å‰45ä¸ªå­—ç¬¦  
    return json_media_name_part_cut, ext_in_stem, json_dup_suffix


# é˜¶æ®µ 2: æŸ¥æ‰¾åŒ¹é…çš„ JSON æ–‡ä»¶
def find_matching_json(media_file, all_json_files):
    '''
    find_matching_json çš„ Docstring
    ç»™å®šä¸€ä¸ªmedia_file, ä»all_json_filesä¸­å¯»æ‰¾åŒ¹é…çš„JSONæ–‡ä»¶
    ä¾æ®æ–‡ä»¶åå‰45ä¸ªå­—ç¬¦è¿›è¡ŒåŒ¹é…, è€ƒè™‘å»é‡ç¼–å·çš„æƒ…å†µ
    '''
    media_fullname_cut, media_stem_cut, media_dup_suffix, media_fullname_no_dup_cut, media_stem_no_dup_cut = get_media_name_part_cut(media_file)
    # 1. å½“jsonæ–‡ä»¶å***å«***media_ext
    for json_file in all_json_files:
        json_media_name_part_cut, ext_in_stem, json_dup_suffix = get_json_media_name_part_cut(json_file)  # è·å–å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†çš„å‰45ä¸ªå­—ç¬¦
        if media_file.parent == json_file.parent and ext_in_stem:
            # ***æ— ***å»é‡ç¼–å·
            if not json_dup_suffix and (media_fullname_cut == json_media_name_part_cut):
                print(f"E1D0.åŒ¹é…æˆåŠŸ: {media_file} <--> {json_file}")
                return json_file
            # ***æœ‰***å»é‡ç¼–å·
            elif media_dup_suffix and json_dup_suffix and (media_dup_suffix == json_dup_suffix) and (media_fullname_no_dup_cut == json_media_name_part_cut):
                print(f"E1D1.åŒ¹é…æˆåŠŸ: {media_file} <--> {json_file}")
                return json_file 
    # 2. å½“jsonæ–‡ä»¶å***ä¸å«***media_ext
    for json_file in all_json_files:
        json_media_name_part_cut, ext_in_stem, json_dup_suffix = get_json_media_name_part_cut(json_file)  # è·å–å¯èƒ½çš„åª’ä½“æ–‡ä»¶åéƒ¨åˆ†çš„å‰45ä¸ªå­—ç¬¦
        if (media_file.parent == json_file.parent) and not ext_in_stem:
            # ***æ— ***å»é‡ç¼–å·
            if not json_dup_suffix and (media_stem_cut == json_media_name_part_cut):
                print(f"E0D0.åŒ¹é…æˆåŠŸ: {media_file} <--> {json_file}")
                return json_file
            # ***æœ‰***å»é‡ç¼–å·
            elif media_dup_suffix and json_dup_suffix and (media_dup_suffix == json_dup_suffix) and (media_stem_no_dup_cut == json_media_name_part_cut):
                print(f"E0D1.åŒ¹é…æˆåŠŸ: {media_file} <--> {json_file}")
                return json_file
    print(f"é€šè¿‡find_matching_jsonæœªæ‰¾åˆ°åŒ¹é…çš„JSONæ–‡ä»¶ for {media_file}")
    return None  # æœªæ‰¾åˆ°åŒ¹é…çš„ JSON æ–‡ä»¶


def live_photo_treat(media_file, matched_pairs):
    '''
    live_photo_treat çš„ Docstring
    å¯¹äºå¯èƒ½æ˜¯ live photo ç±»å‹çš„åª’ä½“æ–‡ä»¶ï¼Œä»å·²åŒ¹é…çš„åŒåå›¾ç‰‡æ–‡ä»¶ä¸­å¯»æ‰¾å¹¶å»ºç«‹å¯¹åº”çš„ JSON æ–‡ä»¶
    '''
    media_fullname = media_file.name  # å¸¦æ‰©å±•åçš„å®Œæ•´æ–‡ä»¶å
    media_stem = media_file.stem  # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
    media_ext = media_file.suffix  # æ–‡ä»¶æ‰©å±•å

    # åˆ¤æ–­å¼€å§‹
    if media_ext.lower() in video_extensions:
        for ref_media_file in matched_pairs:
            if (ref_media_file.parent == media_file.parent) and (ref_media_file.suffix.lower() in image_extensions) and media_stem == ref_media_file.stem and matched_pairs[ref_media_file]:
                    json_fullname = media_fullname + ".json"
                    json_file = media_file.parent / json_fullname
                    shutil.copy2(matched_pairs[ref_media_file], json_file)
                    update_json_key_title(media_file, json_file)
                    print(f"LP.åŒ¹é…æˆåŠŸ: {media_file} <--> {json_file}")
                    return json_file

    print(f"é€šè¿‡live_photo_treatæœªæ‰¾åˆ°åŒ¹é…çš„JSONæ–‡ä»¶ for {media_file}")
    return None  # æœªæ‰¾åˆ°åŒ¹é…çš„ JSON æ–‡ä»¶
    

def find_matching_pairs(all_media_files, all_json_files):
    '''
    find_matching_pairs çš„ Docstring
    åŒ¹é…åª’ä½“æ–‡ä»¶ä¸ JSON æ–‡ä»¶ï¼Œè¿”å›åŒ¹é…å¯¹å­—å…¸
    '''
    # 0. åˆ†ç¦»å›¾ç‰‡å’Œè§†é¢‘æ–‡ä»¶åˆ—è¡¨
    all_image_files = [f for f in all_media_files if f.suffix.lower() in image_extensions]
    all_video_files = [f for f in all_media_files if f.suffix.lower() in video_extensions]
    # 1. å…ˆå¤„ç†å›¾ç‰‡æ–‡ä»¶çš„åŒ¹é…, ä¿è¯å›¾ç‰‡ä¼˜å…ˆåŒ¹é…, æ‰¾ä¸åˆ°çš„åŒåè§†é¢‘å¯ä»¥é€šè¿‡ live photo å¤„ç†
    print(f"--- é˜¶æ®µ 2.1: å¯»æ‰¾imageæ–‡ä»¶çš„åŒ¹é… ---")
    matched_pairs = dict.fromkeys(all_image_files, None)
    for media_file in list(matched_pairs.keys()):
        if matched_pairs[media_file] is None:
            json_file = find_matching_json(media_file, all_json_files)
            if json_file:
                matched_pairs[media_file] = json_file
                all_json_files.remove(json_file)  # ç§»é™¤å·²åŒ¹é…çš„ JSON æ–‡ä»¶ï¼Œé˜²æ­¢é‡å¤ä½¿ç”¨
    # 2. å†å¤„ç†è§†é¢‘æ–‡ä»¶çš„åŒ¹é…
    print(f"--- é˜¶æ®µ 2.2: å¯»æ‰¾videoæ–‡ä»¶çš„åŒ¹é… ---")
    matched_pairs.update(dict.fromkeys(all_video_files, None))
    for media_file in list(matched_pairs.keys()):
        if matched_pairs[media_file] is None and media_file.suffix.lower() in video_extensions:
            json_file = find_matching_json(media_file, all_json_files)
            if json_file:
                matched_pairs[media_file] = json_file
                all_json_files.remove(json_file)  # ç§»é™¤å·²åŒ¹é…çš„ JSON æ–‡ä»¶ï¼Œé˜²æ­¢é‡å¤ä½¿ç”¨
    # 3. å†å¤„ç†live photoå¯ç–‘è§†é¢‘æ–‡ä»¶çš„åŒ¹é…
    print(f"--- é˜¶æ®µ 2.3: å¤„ç†live photoå¯ç–‘videoæ–‡ä»¶çš„åŒ¹é… ---")
    for media_file in list(matched_pairs.keys()):
        if matched_pairs[media_file] is None and media_file.suffix.lower() in video_extensions:
            json_file = live_photo_treat(media_file, matched_pairs)
            if json_file:
                matched_pairs[media_file] = json_file

    # 4. å–„åæ¸…ç†
    print(f"--- é˜¶æ®µ 2.4: å–„åæ¸…ç† ---")
    matched_pairs = cleanup_matched_pairs(matched_pairs)
    cleanup_unmatched_json(all_json_files)

    return matched_pairs


def cleanup_matched_pairs(matched_pairs):
    '''
    cleanup_matched_pairs çš„ Docstring
    æ¸…ç†åŒ¹é…å¯¹å­—å…¸ï¼Œç§»é™¤æœªåŒ¹é…çš„é¡¹
    '''
    # 1. åˆ›å»ºå¾…åˆ é™¤é”®çš„åˆ—è¡¨
    keys_to_delete = []
    for media_file in matched_pairs:
        if matched_pairs[media_file] is None:
            try:
                if media_file.anchor == '':
                    media_relative_path = media_file
                else:
                    media_relative_path = media_file.relative_to(media_file.anchor)
                target_dir = Path("unmatched") / media_relative_path.parent
                target_dir.mkdir(parents=True, exist_ok=True)
                target_path = target_dir / media_file.name
                print(f"[æ¸…ç†] æ­£åœ¨ç§»åŠ¨æœªåŒ¹é… MEDIA æ–‡ä»¶: {media_file} -> {target_path}")
                logging.info(f"[æ¸…ç†] æœªåŒ¹é… MEDIA æ–‡ä»¶: {media_file} -> {target_path}")
                shutil.move(str(media_file), str(target_path))
            except Exception as e:
                logging.error(f"[æ¸…ç†å¤±è´¥] ç§»åŠ¨æœªåŒ¹é…æ–‡ä»¶: {media_file} -> {target_path}, é”™è¯¯: {e}")
            keys_to_delete.append(media_file)
    # 2. åˆ é™¤æœªåŒ¹é…çš„é”®
    for key in keys_to_delete:
        del matched_pairs[key]

    return matched_pairs


def cleanup_unmatched_json(all_json_files):
    '''
    cleanup_unmatched_json çš„ Docstring
    æ¸…ç†æœªåŒ¹é…çš„ JSON æ–‡ä»¶ï¼Œç§»åŠ¨åˆ° unmatched ç›®å½•
    '''
    for json_file in all_json_files:
        if json_file and json_file.exists():
            try:
                if json_file.anchor == '':
                    json_relative_path = json_file
                else:
                    json_relative_path = json_file.relative_to(json_file.anchor)
                target_dir = Path("unmatched") / json_relative_path.parent
                target_dir.mkdir(parents=True, exist_ok=True)
                target_path = target_dir / json_file.name
                print(f"[æ¸…ç†] æ­£åœ¨ç§»åŠ¨æœªåŒ¹é… JSON æ–‡ä»¶: {json_file} -> {target_path}")
                logging.info(f"[æ¸…ç†] æœªåŒ¹é… JSON æ–‡ä»¶: {json_file} -> {target_path}")
                shutil.move(str(json_file), str(target_path))
            except Exception as e:
                logging.error(f"[æ¸…ç†å¤±è´¥] ç§»åŠ¨æœªåŒ¹é… JSON æ–‡ä»¶: {json_file} -> {target_path}, é”™è¯¯: {e}")


def let_ext_correct(media_file, json_file):
    # æ£€æµ‹æ–‡ä»¶ç±»å‹
    kind = filetype.guess(media_file)
    if kind is None:
        print(f"! æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹: {media_file}")
        return media_file, json_file
    detected_extension = f".{kind.extension}"
    current_extension = Path(media_file).suffix.lower()
    if detected_extension == ".jpeg":  # jpgæœ‰ä¸¤ç§æ‰©å±•å
        detected_extension = ".jpg"
    if current_extension == ".jpeg":
        current_extension = ".jpg"
    if detected_extension != current_extension:
        # æ„å»ºæ–°æ–‡ä»¶å
        new_media_fullname = Path(media_file).stem + detected_extension
        new_media_file = Path(media_file).with_name(new_media_fullname)
        count = 1
        while new_media_file.exists():  # å¦‚æœæ–°æ–‡ä»¶åå·²å­˜åœ¨ï¼Œæ·»åŠ æ•°å­—åç¼€
            if re.search(r"_\d{1,2}$", Path(new_media_file).stem):
                new_media_fullname = re.sub(r"_\d{1,2}$", f"_{count}", Path(new_media_file).stem) + detected_extension
            else:
                new_media_fullname = f"{Path(new_media_file).stem}_{count}{detected_extension}"
            new_media_file = Path(media_file).with_name(new_media_fullname)
            count += 1
        # é‡å‘½ååª’ä½“æ–‡ä»¶
        try: 
            print(f"- æ›´æ­£æ‰©å±•å: {Path(media_file).name} --> {Path(new_media_file).name}")
            Path(media_file).rename(new_media_file)
            media_file = new_media_file  # æ›´æ–°media_fileä¸ºæ–°æ–‡ä»¶å
        except Exception as e:
            logging.error(f"! é‡å‘½åæ–‡ä»¶ {Path(media_file).name} æ—¶å‡ºé”™: {e}")
        # é‡å‘½åå¯¹åº”çš„jsonæ–‡ä»¶
        if json_file:
            json_fullname = Path(json_file).name
            try:
                new_json_fullname = Path(media_file).name + ".json"
                new_json_file = Path(json_file).with_name(new_json_fullname)
                print(f"- æ›´æ­£å¯¹åº”jsonæ–‡ä»¶å: {Path(json_file).name} --> {Path(new_json_file).name}")
                Path(json_file).rename(new_json_file)
                json_file = new_json_file  # æ›´æ–°json_fileä¸ºæ–°æ–‡ä»¶å
            except Exception as e:
                logging.error(f"! é‡å‘½åæ–‡ä»¶ {Path(json_file).name} æ—¶å‡ºé”™: {e}")
        # æ›´æ–°jsonä¸­çš„titleå€¼
        if json_file:
            update_json_key_title(media_file, json_file)

    return media_file, json_file  # è¿”å›æ›´æ–°åçš„æ–‡ä»¶è·¯å¾„


def correct_ext_of_matched_pairs(matched_pairs):
    '''
    correct_ext_of_matched_pairs çš„ Docstring
    å¯¹åŒ¹é…å¯¹ä¸­çš„åª’ä½“æ–‡ä»¶è¿›è¡Œæ‰©å±•åæ›´æ­£
    '''
    for media_file in list(matched_pairs.keys()):
        json_file = matched_pairs[media_file]
        new_media_file, new_json_file = let_ext_correct(media_file, json_file)
        # å¦‚æœæ–‡ä»¶åæœ‰å˜æ›´ï¼Œæ›´æ–°åŒ¹é…å¯¹å­—å…¸çš„é”®å’Œå€¼
        if new_media_file != media_file:
            matched_pairs[new_media_file] = matched_pairs.pop(media_file)
        if new_json_file != json_file:
            matched_pairs[new_media_file] = new_json_file
    return matched_pairs


def update_media_metadata(media_file, json_file):
    """
    ä½¿ç”¨ ExifTool å°† JSON ä¿¡æ¯å†™å…¥åª’ä½“æ–‡ä»¶ (æ”¯æŒ JPG, HEIC, MP4, MOV)
    """
    try:
        # 1. è¯»å– JSON æ•°æ®
        data = json.loads(json_file.read_text(encoding="utf-8"))
        # 2. è·å–å¹¶å¤„ç†æ—¶é—´æˆ³
        timestamp = None
        if "photoTakenTime" in data and "timestamp" in data["photoTakenTime"]:
            timestamp = float(data["photoTakenTime"]["timestamp"])
        elif "creationTime" in data and "timestamp" in data["creationTime"]:
            timestamp = float(data["creationTime"]["timestamp"])
        if not timestamp:
            print(f"! JSONä¸­æœªæ‰¾åˆ°æ—¶é—´æˆ³, è·³è¿‡")
            return
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸º ExifTool éœ€è¦çš„å­—ç¬¦ä¸²æ ¼å¼ "YYYY:MM:DD HH:MM:SS"
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ local_timezone (åœ¨è„šæœ¬å¼€å¤´å®šä¹‰çš„)
        timestamp_localized = datetime.fromtimestamp(timestamp, local_timezone)
        date_str = timestamp_localized.strftime("%Y:%m:%d %H:%M:%S")
        # 3. å‡†å¤‡ ExifTool å‘½ä»¤å‚æ•°
        cmd = [
            "exiftool", 
            "-charset filename=utf8",  # å¤„ç†æ–‡ä»¶åä¸­çš„éASCIIå­—ç¬¦
            "-overwrite_original",   # -overwrite_original: ç›´æ¥è¦†ç›–åŸæ–‡ä»¶ï¼Œä¸ç”Ÿæˆ _original å¤‡ä»½
            "-P",   # -P: ä¿ç•™æ–‡ä»¶ç³»ç»Ÿä¿®æ”¹æ—¶é—´ (è™½ç„¶æˆ‘ä»¬åé¢ä¼šæ‰‹åŠ¨æ”¹ï¼Œä½†åŠ ä¸ªä¿é™©)
            "-u",  # -u: å…è®¸å†™å…¥æœªçŸ¥æ ‡ç­¾ (å¢åŠ å…¼å®¹æ€§)
            f"-AllDates={date_str}",    # å†™å…¥æ‰€æœ‰å¸¸è§æ—¥æœŸæ ‡ç­¾ (DateTimeOriginal, CreateDate, ModifyDate)
        ]
        # 4. å¤„ç† GPS ä¿¡æ¯
        geo = data.get('geoDataExif') or data.get('geoData')
        if geo and geo.get('latitude', 0.0) != 0.0:
            lat = geo['latitude']
            lng = geo['longitude']
            alt = geo.get('altitude', 0)
            # ExifTool éå¸¸æ™ºèƒ½ï¼Œç›´æ¥ä¼ å¸¦ç¬¦å·çš„æµ®ç‚¹æ•°ï¼Œå®ƒä¼šè‡ªåŠ¨è®¡ç®— Ref (N/S, E/W)
            cmd.append(f"-GPSLatitude={lat}")
            cmd.append(f"-GPSLatitudeRef={lat}")
            cmd.append(f"-GPSLongitude={lng}")
            cmd.append(f"-GPSLongitudeRef={lng}")
            cmd.append(f"-GPSAltitude={alt}")
            # é’ˆå¯¹è§†é¢‘æ–‡ä»¶çš„ç‰¹æ®Š GPS æ ‡ç­¾ (QuickTime)
            # æ ¼å¼é€šå¸¸ä¸º "+23.1250+113.3393/"
            if media_file.suffix.lower() in video_extensions:
                 # ç®€å•çš„è§†é¢‘ GPS æ ¼å¼åŒ–ï¼ŒExifTool å¯¹è§†é¢‘ GPS æ”¯æŒç¨å¾®å¤æ‚ä¸€ç‚¹ï¼Œè¿™è¡Œå°è¯•å†™å…¥é€šç”¨çš„ Keys
                cmd.append(f"-Keys:GPSCoordinates={lat}, {lng}, {alt}")
        # 5. æ·»åŠ ç›®æ ‡æ–‡ä»¶è·¯å¾„
        # å¿…é¡»æŠŠè·¯å¾„è½¬ä¸ºå­—ç¬¦ä¸²
        cmd.append(str(media_file))
        # 6. æ‰§è¡Œå‘½ä»¤
        # Windowsä¸‹å¦‚æœä¸æŠŠ exiftool.exe æ”¾ PATHï¼Œå¯èƒ½éœ€è¦æŒ‡å®šå®Œæ•´è·¯å¾„ï¼Œå¦‚ ".\exiftool.exe"
        # è¿™é‡Œå‡è®¾ä½ æŠŠå®ƒæ”¾åœ¨äº†åŒç›®å½•æˆ– PATH é‡Œ
        exiftool_cmd = "exiftool" 
        if os.path.exists("exiftool.exe"): # å¦‚æœå½“å‰ç›®å½•ä¸‹æœ‰
            exiftool_cmd = os.path.abspath("exiftool.exe")
        cmd[0] = exiftool_cmd
        print(f"  - æ­£åœ¨è°ƒç”¨ ExifTool å†™å…¥å…ƒæ•°æ®...")
        # capture_output=True å¯ä»¥éšè—æ§åˆ¶å°çš„å¤§é‡è¾“å‡ºï¼Œåªçœ‹æŠ¥é”™
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âˆš ExifTool å†™å…¥æˆåŠŸ")
        else:
            logging.error(f"ExifTool æŠ¥é”™ {media_file.name}: {result.stderr}")
            print(f"! ExifTool æŠ¥é”™: {result.stderr.strip()}")
        # 7. (å¯é€‰) å†æ¬¡å¼ºåˆ¶åˆ·æ–°æ–‡ä»¶ç³»ç»Ÿæ—¶é—´
        # è™½ç„¶ ExifTool åŠ äº† -FileModifyDateï¼Œä½†æœ‰æ—¶å€™ Python çš„ os.utime æ›´å‡†
        set_file_times(media_file, timestamp)
        set_file_times(json_file, timestamp)
    except Exception as e:
        logging.error(f"å…ƒæ•°æ®æ›´æ–°æµç¨‹å‡ºé”™ {media_file.name}: {e}")
        print(f"! é”™è¯¯: {e}")


def update_media_metadata_mp(matched_pairs):
    '''
    update_media_metadata_with_matched_pairs çš„ Docstring
    å¯¹åŒ¹é…å¯¹ä¸­çš„åª’ä½“æ–‡ä»¶è¿›è¡Œå…ƒæ•°æ®æ›´æ–°
    '''
    for media_file in list(matched_pairs.keys()):
        json_file = matched_pairs[media_file]
        if json_file:
            print(f"--- æ­£åœ¨ä½¿ç”¨ {json_file} æ›´æ–°å…ƒæ•°æ®: {media_file} ---")
            update_media_metadata(media_file, json_file)
    return matched_pairs

def update_media_metadata_mp_mt(matched_pairs):
    '''
    update_media_metadata_with_matched_pairs_with_multi_threading çš„ Docstring
    ç”¨å¤šçº¿ç¨‹å¯¹åŒ¹é…å¯¹ä¸­çš„åª’ä½“æ–‡ä»¶è¿›è¡Œå…ƒæ•°æ®æ›´æ–°
    '''
    tasks = list(matched_pairs.items())
    workers = os.cpu_count() or 8
    with ThreadPoolExecutor(max_workers=workers) as executor: # ä¾‹å¦‚ä½¿ç”¨8ä¸ªçº¿ç¨‹
        # æäº¤é˜¶æ®µ 4 çš„æ‰€æœ‰å…ƒæ•°æ®æ›´æ–°ä»»åŠ¡
        futures = {executor.submit(update_media_metadata, media_path, json_path): (media_path, json_path) for media_path, json_path in tasks}
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in as_completed(futures):
            # å¤„ç†ç»“æœæˆ–å¼‚å¸¸
            # ğŸš¨ æŸ¥æ‰¾åŸå§‹æ–‡ä»¶è·¯å¾„
            media_path, json_path = futures[future]  
            try:
                # å°è¯•è·å–ä»»åŠ¡ç»“æœï¼ˆè¿™ä¹Ÿä¼šè§¦å‘å¼‚å¸¸ï¼Œå¦‚æœä»»åŠ¡å¤±è´¥ï¼‰
                future.result()     
            except Exception as e:
                # æŠ¥å‘Šé”™è¯¯æ—¶ï¼Œå¯ä»¥æ˜ç¡®æŒ‡å‡ºæ˜¯å“ªä¸ªæ–‡ä»¶å‡ºäº†é—®é¢˜
                logging.error(f"--- é˜¶æ®µ 4:å¤„ç†æ–‡ä»¶ {media_path.name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            pass


# â­ ä¸»å‡½æ•° (ä¿®æ”¹ä¸ºä¸¤é˜¶æ®µå¤„ç†) â­
def repair_media_files(directory):
    # 2.1 æ„é€ åŸºäºç›®å½•çš„æ—¥å¿—æ–‡ä»¶å
    # è§„èŒƒåŒ–ç›®å½•åï¼Œé˜²æ­¢ç‰¹æ®Šå­—ç¬¦
    sanitized_dir = Path(directory).name.replace(os.sep, '_').replace(':', '_').replace(' ', '_')
    log_filename = f"media_file_repair_{sanitized_dir}.log"

    # 2.2 é…ç½®æ—¥å¿—ï¼ˆåªåœ¨è¿™ä¸ªå®ä¾‹ä¸­ç”Ÿæ•ˆï¼‰
    # æ³¨æ„ï¼šè¦ç”¨ filemode='w' æ¸…ç©ºæ—§æ—¥å¿—ï¼Œæˆ–ç”¨ 'a' è¿½åŠ 
    logging.basicConfig(filename=log_filename, level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s", encoding="utf-8", filemode='a')
    print(f"æ—¥å¿—æ–‡ä»¶: {log_filename}")

    # --- é˜¶æ®µ 1: å¯»æ‰¾åª’ä½“æ–‡ä»¶ä¸é…ç½®æ–‡ä»¶ --- éå†ï¼šæ‰«ææ‰€æœ‰æ–‡ä»¶ï¼Œå»ºç«‹åª’ä½“æ–‡ä»¶å’Œ JSON æ–‡ä»¶çš„åˆå§‹åˆ—è¡¨
    print(f"--- é˜¶æ®µ 1: å¯»æ‰¾åª’ä½“æ–‡ä»¶ä¸é…ç½®æ–‡ä»¶ ---")
    all_media_files = collect_all_files(directory, media_extensions)
    all_json_files = collect_all_files(directory, json_extensions)      
    all_json_files = set(all_json_files)  # è½¬ä¸ºé›†åˆä»¥ä¾¿åç»­ç§»é™¤å·²åŒ¹é…çš„ JSON æ–‡ä»¶      
    print(f"æ‰«æå®Œæˆã€‚å‘ç° {len(all_media_files)} ä¸ªåª’ä½“æ–‡ä»¶ï¼Œ{len(all_json_files)} ä¸ª JSON æ–‡ä»¶ã€‚")

    # --- é˜¶æ®µ 2: åŒ¹é…åª’ä½“æ–‡ä»¶ä¸é…ç½®æ–‡ä»¶ --- å»ºç«‹é…å¯¹åˆ—è¡¨
    print(f"--- é˜¶æ®µ 2: åŒ¹é…åª’ä½“æ–‡ä»¶ä¸é…ç½®æ–‡ä»¶ ---")
    matched_pairs = find_matching_pairs(all_media_files, all_json_files)
    print(f"åŒ¹é…å®Œæˆã€‚å…±åŒ¹é…åˆ° {len(matched_pairs) - list(matched_pairs.values()).count(None)} å¯¹åª’ä½“æ–‡ä»¶ä¸ JSON æ–‡ä»¶ã€‚")
    
    # --- é˜¶æ®µ 3: æ›´æ­£é”™è¯¯æ‰©å±•å ---
    print(f"--- é˜¶æ®µ 3: æ›´æ­£é”™è¯¯æ‰©å±•å ---")
    matched_pairs = correct_ext_of_matched_pairs(matched_pairs)
    print(f"æ‰©å±•åæ›´æ­£å®Œæˆã€‚")
    
    # --- é˜¶æ®µ 4: æ›´æ–°å…ƒæ•°æ® ---
    print(f"--- é˜¶æ®µ 4: æ›´æ–°å…ƒæ•°æ® ---")
    update_media_metadata_mp_mt(matched_pairs)
    
    
    print(f"å…ƒæ•°æ®æ›´æ–°å®Œæˆã€‚")

    



if __name__ == "__main__":
    # ä½¿ç”¨argparseè§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="ä¿®å¤åª’ä½“æ–‡ä»¶å…ƒæ•°æ®")
    parser.add_argument("directory", help="éœ€è¦å¤„ç†çš„ç›®å½•è·¯å¾„")
    args = parser.parse_args()

    repair_media_files(args.directory)